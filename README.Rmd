---
output:
  md_document:
    variant: gfm
---


```{r setup, message = FALSE}
#devtools::install_github("thomazbastiaanssen/volatility")
library(tidyverse)
library(deleuze)
library(patchwork)
library(Tjazi)
data = volatility::vola_genus_table$Validation_Pre_Control_2

data

```

```{r estimation of the geometric mean}
#comparing the distributions
#comparing mean and SD of the resampled and approximated distributions
knitr::kable(t(data.frame("observed" = 
                            c("mean"   = mean(sampleGeomMeam(samples = 10000, count_sample = data, log_transformed = T)), 
                              "sd"     = sd(sampleGeomMeam(samples = 10000, count_sample = data, log_transformed = T))), 
                          "approximated" = 
                            c("mean" = mean(getBetaMeans(data, log_transformed = T)), 
                              "sd"   = sqrt(sum(getBetaVars(count_sample = data, log_transformed = T)) /(length(data)* length(data)))))
               )
             )


#Overlaid:
plot(density(sampleGeomMeam(samples = 10000, count_sample = data, log_transformed = T)), 
     col = "red", main = "Comparing the sampled geometric mean (red)\n to the approximated distribution (black)")

lines(density(sampleGeomMeanApprox(samples = 10000, count_sample = data, log_transformed = T)))


```

```{r comparing CLR to approx, out.width = '100%', fig.height = 8}
#real sampled data

a = sampleCLR(10000, data) %>%
  data.frame() %>%
  mutate(sample = as.character(1:10000)) %>%
  pivot_longer(!sample) %>%
  
  filter(name %in% paste0("X", 1:20)) %>%
  mutate(type = "sampled")

#sampled from approximation
b = sampleCLRApprox(samples = 10000, data) %>%
  data.frame() %>%
  mutate(sample = as.character(1:10000)) %>% 
  pivot_longer(!sample) %>%
  
  filter(name %in% paste0("X", 1:20)) %>%
  mutate(type = "approx")

rbind(a, b) %>%
  filter(name %in% paste0("X", 1:15)) %>%

  mutate(name = paste(name, "n counts =", data[1:15])) %>%
  mutate(name = factor(name, levels = paste0("X", 1:15, " n counts = ", data[1:15]))) %>%
  

  ggplot() +
  aes(x = value, fill = type) +
  
  geom_density(alpha = 2/3) +
  
  facet_wrap(~name, scales = "free", ncol = 3) +
  theme_bw() +
  theme(legend.position = 'bottom') + 
  ggtitle("Notice that the zero-count features such as X13\n have a much higher spread than high rollers like X7")


```

For benchmarking click [Here](https://github.com/thomazbastiaanssen/deleuze/blob/main/docs/benchmarking.md) 
(put on its own page as it's slow to knit)



```{r comparing CLR to approx entire table, out.width = '100%', fig.height = 8}
#real sampled data
data = volatility::vola_genus_table


a = data %>% 
  Tjazi::clr_c() %>%
  t 

b = data %>% 
  getTableMeans() %>%
  t

#Apply the base R principal component analysis function on our CLR-transformed data.

data.a.pca = rbind(a, b) %>% 
  prcomp()

#Extract the amount of variance the first four components explain for plotting. 
pc1 <- round(data.a.pca$sdev[1]^2/sum(data.a.pca$sdev^2),4) * 100
pc2 <- round(data.a.pca$sdev[2]^2/sum(data.a.pca$sdev^2),4) * 100
pc3 <- round(data.a.pca$sdev[3]^2/sum(data.a.pca$sdev^2),4) * 100
pc4 <- round(data.a.pca$sdev[4]^2/sum(data.a.pca$sdev^2),4) * 100

#Extract the scores for every sample for the first four components for plotting. 
pca  = data.frame(PC1 = data.a.pca$x[,1], 
                  PC2 = data.a.pca$x[,2], 
                  PC3 = data.a.pca$x[,3], 
                  PC4 = data.a.pca$x[,4])

pca$Type = rep(c("lognorm", "estimated"), each = 120 )
pca$ID   = paste0("s",1:120)



#First, the main plot. Plot the first two components of the PCA
ggplot(pca, aes(x       = PC1,
                y       = PC2,
                fill    = Type)) +  
  
  #Create the points and ellipses
  geom_path(aes(group = ID), col = "black") +
  geom_point(size=3, col = "black", shape = 21) + 
  #Adjust appearance
  
  #Adjust labels
  ggtitle("lognorm vs new method") + 
  xlab(paste("PC1: ", pc1,  "%", sep="")) + 
  ylab(paste("PC2: ", pc2,  "%", sep="")) +
  theme_bw() +
  theme(legend.position = 'bottom') 
  
plot(x = c(unlist(Tjazi::clr_c(data))),
     y = c(getTableMeans(data)))

```



Dividing by the variance of the CLR transformed data before transforming reduces dispersion. 
```{r reduce overdispersion, out.width = '100%', fig.height = 8}
set.seed(12345)

library(tidyverse)
library(deleuze)

#Create some dummy data with known ground truth
vec = round(runif(n = 100, min = 1, max = 100))


x = exp(c(
  seq(1,4.95,by = 0.05), 
  seq(5,1.05,by = -0.05)
  ))

y = c(x[41:160],x[1:40])
  

z = rep(1,160)

xpart = sapply(X = vec[ 1: 25], FUN = function(f){(f*x)}, simplify = T) 
ypart = sapply(X = vec[26: 50], FUN = function(f){(f*y)}, simplify = T) 
zpart = sapply(X = vec[51:100], FUN = function(f){(f*z)}, simplify = T)


dummy = do.call(cbind, list(xpart,ypart,zpart)) 

  
rownames(dummy) = paste("sample",  1:160, sep = "_")
colnames(dummy) = paste("microbe", 1:100, sep = "_") 


res_dummy = apply(dummy, 1,FUN = function(x){
  table(factor(sample(colnames(dummy), prob = x, replace = T,size = 10000 ),levels = colnames(dummy)))
  
})

par(mfrow = c(1,2))

plot(c(unlist(dummy[1:10,] %>% 
                t() %>% 
                Tjazi::clr_c() )),
     
     c(
       getTableMeans(res_dummy[,1:10]/
                       (rowMeans(getTableVars(res_dummy[,1:10]))))
          )
)


plot(c(unlist(dummy[1:10,] %>% 
                t() %>% 
                Tjazi::clr_c() )),
     c(unlist(res_dummy[,1:10] %>% 
                
                Tjazi::clr_c() )))
  
```



```{r fib comparison, out.width = '100%', fig.height = 6}

x <- 0
y <- 1
fib <- c()
while (x < 2000 & y < 2000){
  x <- x + y
  y <- x + y
  fib = c(fib, x, y)
}
length(fib)


res_fib = sapply(X = rep(seq(1000,10000, by = 100), each = 10),FUN = function(x){
  table(factor(sample(paste0("size_",fib), prob = fib, replace = T,size = x ),levels = paste0("size_",fib)))
  
})

colnames(res_fib) = paste0(rep(seq(1000,10000, by = 100), each = 10))
View(res_fib)

res_old <- res_fib %>% 
  clr_c() %>%
  rownames_to_column("feature") %>%
  pivot_longer(!feature) %>%
  mutate(name = str_remove(name, pattern = "\\..*")) %>%
  add_column("type" = "old")

res_new <- (res_fib/rowMeans(getTableVars(res_fib))) %>%
  getTableMeans() %>%
  data.frame() %>%
  rownames_to_column("feature") %>%
  pivot_longer(!feature) %>%
  mutate(name = str_remove(name, pattern = "\\..*")) %>%
  mutate(name = str_remove(name, pattern = "X")) %>%
  add_column("type" = "new")


rbind(res_old, res_new) %>%
  mutate(name = as.numeric(name)) %>%
  mutate(feature = factor(feature,  levels = paste0("size_",fib))) %>%
  filter(feature %in% paste0("size_",fib)[1:8]) %>%
  ggplot() +
  aes(x = name, y = value, fill = type) +
  
  geom_point(shape = 21) +
  facet_wrap(~feature, scales = "free") +
  theme_bw()
  


res_old <- res_fib %>% 
  clr_c() %>%
  rownames_to_column("feature") %>%
  pivot_longer(!feature) %>%
  mutate("type" = "old")

res_new <- (res_fib/rowMeans(getTableVars(res_fib))) %>%
  getTableMeans() %>%
  data.frame() %>%
  rownames_to_column("feature") %>%
  pivot_longer(!feature) %>%
  mutate(name = str_remove(name, pattern = "X")) %>%
  add_column("type" = "new")


rbind(res_old, res_new) %>%

  filter(feature %in% paste0("size_",fib)[1:12]) %>%
  pivot_wider(names_from = "type") %>%
  mutate(feature = factor(feature,  levels = paste0("size_",fib))) %>%
  mutate(name = str_remove(name, pattern = "\\..*")) %>%
  mutate(name = as.numeric(name)) %>%
  
  ggplot() +
  aes(x = old, y = new, fill = name) +
  
  geom_point(shape = 21, alpha = 3/4) +
  scale_fill_gradient(low = "#4575b4", high = "#d73027") +
  facet_wrap(~feature, scales = "free", ncol = 4) +
  theme_bw()
```

}